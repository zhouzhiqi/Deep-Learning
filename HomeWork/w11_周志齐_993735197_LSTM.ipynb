{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>WordEmbedding<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#作业成果\" data-toc-modified-id=\"作业成果-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>作业成果</a></span><ul class=\"toc-item\"><li><span><a href=\"#sample.py输出结果\" data-toc-modified-id=\"sample.py输出结果-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>sample.py输出结果</a></span></li><li><span><a href=\"#输出结果分析与认识\" data-toc-modified-id=\"输出结果分析与认识-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>输出结果分析与认识</a></span></li></ul></li><li><span><a href=\"#RNN理解与心得体会\" data-toc-modified-id=\"RNN理解与心得体会-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>RNN理解与心得体会</a></span><ul class=\"toc-item\"><li><span><a href=\"#基础RNN\" data-toc-modified-id=\"基础RNN-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>基础RNN</a></span></li><li><span><a href=\"#LSTM\" data-toc-modified-id=\"LSTM-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>LSTM</a></span></li><li><span><a href=\"#RNN代码分析\" data-toc-modified-id=\"RNN代码分析-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>RNN代码分析</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作业成果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## sample.py输出结果\n",
    " \n",
    "```sh\n",
    "INFO:tensorflow:Restoring parameters from ./output/model.ckpt-53835\n",
    "2018-05-16 16:26:39,995 - INFO - tf_logging.py:82 - Restoring parameters from ./output/model.ckpt-53835\n",
    "2018-05-16 16:26:40,029 - DEBUG - sample.py:53 - restore from [./output/model.ckpt-53835]\n",
    "2018-05-16 16:26:40,670 - DEBUG - sample.py:88 - ==============[江神子]==============\n",
    "2018-05-16 16:26:40,671 - DEBUG - sample.py:89 - 江神子\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "刘UNK\n",
    "\n",
    "水调歌头（和韵）\n",
    "\n",
    "一里春风，一番春月，一番春色。一里春风，一番一里，一番春月。\n",
    "\n",
    "一枝春色，一番春去，一番\n",
    "2018-05-16 16:26:41,129 - DEBUG - sample.py:88 - ==============[蝶恋花]==============\n",
    "2018-05-16 16:26:41,130 - DEBUG - sample.py:89 - 蝶恋花一点春风，一点春风。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "刘UNK\n",
    "\n",
    "水调歌头（和韵）\n",
    "\n",
    "一里春风，一番春月，一番春色。一里春风，一番一里，一点春风。\n",
    "\n",
    "一枝\n",
    "2018-05-16 16:26:41,584 - DEBUG - sample.py:88 - ==============[渔家傲]==============\n",
    "2018-05-16 16:26:41,585 - DEBUG - sample.py:89 - 渔家傲\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "刘UNK\n",
    "\n",
    "水调歌头（和韵）\n",
    "\n",
    "一里春风，一番春月，一番春色。一里春风，一番一里，一番春月。\n",
    "\n",
    "一枝春色，一番春去，一番\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输出结果分析与认识\n",
    "\n",
    "学会了词牌名, 还学会了姓氏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN理解与心得体会"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T03:14:27.521502Z",
     "start_time": "2018-05-16T03:14:27.515507Z"
    }
   },
   "source": [
    "## 基础RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "循环神经网络(Recurrent Neural Network. RNN )是一种特殊的前向传播神经网络,它对于序列化数据如语音和文本等具有很强的建模能力, 广泛的用于自然语言处理中的语音识别以及机器翻译等领域.    \n",
    "标准的RNN由3层构成:输入层、循环层和输出层.   \n",
    "它的特别之处在于模型的循环层. 顾名思义, 循环, 也就是在循环层加入了自连接和互连接, 通过使用一个短序列, 对所有索引进行逐个的扫描来实现短时记忆的功能. \n",
    "简单的基于RBM的模型都是层间节点全连接, 层内节点无连接.    \n",
    "由于单词之间不是独立的, 都是有语义关系的, 而RNN可以充分的利用上下文信息, 记忆当前单词并时时更新这个时刻之前的所有单词的信息, 基于序列从而更好的预测.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于RNN也有梯度消失的问题，因此很难处理长序列的数据, 而RNN的改进算法LSTM(Long Short-Term Memory)可以避免常规RNN的梯度消失的问题.   \n",
    "RNN的改进之处主要的两大点, 一个是细胞状态, 另一个就是门控结构.   \n",
    "细胞状态是除了隐藏状态$h^{(t)}$之外的另一隐藏状态.   \n",
    "门控结构有三个: 遗忘门, 输入门, 输出门  \n",
    "sigmoid激活的输出为(0,1), 可近似看做是概率, 1为保留, 0为遗忘  \n",
    "遗忘门输出$f^{(t)}$由隐藏状态$h^{(t-1)}$和本次序列数据$x^{(t)}$，通过sigmoid激活得到   \n",
    "输入门由隐藏状态$h^{(t-1)}$和本次序列数据$x^{(t)}$，通过sigmoid激活以及tanh激活, 两个激活结果Hadamard乘积得到   \n",
    "细胞状态的输出由上一细胞状态$C^{(t-1)}$和遗忘门输出$f^{(t)}$的乘积, 加上输入门的结果共同得到.   \n",
    "输出门隐藏状态$h^{(t-1)}$和本次序列数据$x^{(t)}$，通过sigmoid激活, 并与本层经过tanh激活过的细胞状态Hadamard乘积得到"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN代码分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "with tf.variable_scope('rnn'):\n",
    "    # 创建lstm_cell\n",
    "    lstm_cell=tf.nn.rnn_cell.BasicLSTMCell(self.dim_embedding,forget_bias=0.0,state_is_tuple=True)\n",
    "    # 对lstm_cell进行Dropout\n",
    "    lstm_cell=tf.nn.rnn_cell.DropoutWrapper(lstm_cell,output_keep_prob=self.keep_prob)\n",
    "    # 重复生成多个lstm_cell并合并为真正的cell\n",
    "    cell=tf.nn.rnn_cell.MultiRNNCell([lstm_cell]*self.rnn_layers,state_is_tuple=True)\n",
    "    # 创建初始的state, 并全部用0填充\n",
    "    self.state_tensor=cell.zero_state(self.batch_size,dtype=tf.float32)\n",
    "    # 激活一个RNN训练\n",
    "    seq_output,final_state=tf.nn.dynamic_rnn(cell,data,initial_state=self.state_tensor,scope='rnnlm')\n",
    "    # 记录最后的state\n",
    "    self.outputs_state_tensor=final_state\n",
    "    #----------------------------------------\n",
    "#flattenit#3x32x128->96x128\n",
    "seq_output_final=tf.reshape(seq_output,[-1,self.dim_embedding])\n",
    "\n",
    "with tf.variable_scope('softmax'):\n",
    "    softmax_w=tf.get_variable(\"softmax_w\",[self.dim_embedding,self.num_words],dtype=tf.float32)\n",
    "    softmax_b=tf.get_variable(\"softmax_b\",[self.num_words],dtype=tf.float32)\n",
    "    #96x128->96x5000\n",
    "    logits=tf.matmul(seq_output_final,softmax_w)+softmax_b\n",
    "    #----------------------------------------------------------------------\n",
    "tf.summary.histogram('logits',logits)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "WordEmbedding",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
